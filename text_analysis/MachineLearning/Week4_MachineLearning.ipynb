{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `머신러닝(기계학습) `\n",
    "\n",
    "- 데이터를 구문 분석하고 해당 데이터를 통해 학습한 후 정보를 바탕으로 결정을 내리기 위해 학습한 내용을 적용하는 알고리즘\n",
    "\n",
    "\n",
    "- 주어진 데이터로 기능을 수행하고, 시간이 지남에 따라 그 기능이 점차 향상됨. \n",
    "\n",
    "\n",
    "- `데이터를 학습시키고, 결과를 예측.`\n",
    "\n",
    "\n",
    "- `지도학습`과 `비지도학습`으로 나뉨\n",
    "\n",
    "----\n",
    "\n",
    "### 1. 머신러닝의 분류\n",
    "### 1) 지도 학습\n",
    "---\n",
    "* 답이 제공되어 나중에 답을 맞출 수 있게 하는 족보같은 개념.    \n",
    "    \n",
    "    * 지도학습은 결국 `답을 찾기 위해 활용하는 알고리즘`. \n",
    "        \n",
    "    * 답이 있는 **`훈련 데이터 (Train Set)`** 를 이용해 학습시킴\n",
    "        \n",
    "    * 그 다음, 우리가 예측하고자 하는 데이터를 평가 데이터, **`테스트 데이터(Test Data)`** 라 하고, 얼마나 정확하게 답을 맞추었느냐에 따라 알고리즘의 성능을 결정.  \n",
    "    \n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "> ### 분류\n",
    ">> #### 1. 범주형 데이터\n",
    ">> 데이터의 값이 숫자가 아닌, A,B,C 등으로 구분되는 데이터. \n",
    "\n",
    "> ### 회귀\n",
    "> `일반적인 관계 특성.` \n",
    ">> #### 2. 연속형 데이터 \n",
    ">> 값들이 어느 범위 내에서 `수치형태`로 존재하는 데이터. \n",
    "    \n",
    " \n",
    "\n",
    "### 2) 비지도 학습\n",
    "---\n",
    "* 답이 제공되지 않은 데이터를 학습시키는 것\n",
    "    * 결국 최종 판단은 사람의 몫\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*!! 어차피 우리는 지도학습만 배울겁니다!!*\n",
    "---\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "### 2. 사이킷런 이용\n",
    "---\n",
    "#### <span style=\"color:blue\"> 1.필요한 모듈들 import</span>\n",
    "\n",
    "~~~python\n",
    "\n",
    "    import numpy as np                                       ## 기초 수학 연산 및 행렬계산\n",
    "    import pandas as pd                                      ## 데이터프레임 사용\n",
    "\n",
    "    from sklearn.model_selection import train_test_split     ## train, test 데이터 분할\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression        ## 선형 회귀분석\n",
    "    from sklearn.linear_model import LogisticRegression      ## 로지스틱 회귀분석\n",
    "    from sklearn import svm                                  ## 서포트 벡터 머신\n",
    "    from sklearn import tree                                 ## 의사결정나무\n",
    "    from sklearn.ensemble import RandomForestClassifier      ## 랜덤포레스트\n",
    "\n",
    "    import matplotlib.pyplot as plt                          ## plot 그릴때 사용\n",
    "    \n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "#### <span style=\"color:blue\"> 2.데이터 전처리 </span>\n",
    "\n",
    "\n",
    "- 텍스트든, 일반 수치형 데이터든 상관없습니다.\n",
    "- 전처리 과정이 생각보다 몹시 중요합니다.\n",
    "- 학습에 도움이 되는 외부 데이터를 첨가하거나, 데이터 일반화, Log Scaling 등을 수행합니다. \n",
    "- MinMax, Standard Scaler 등\n",
    "\n",
    "#### <span style=\"color:blue\">3. 독립변수/종속변수 나눈 후  학습 데이터와 평가 데이터로 구분.</span>\n",
    "\n",
    "\n",
    "\n",
    "~~~python\n",
    "\n",
    "X = Data[['col1','col2']] ## 독립 변수\n",
    "y = Data['종속변수']        ## 종속 변수 \n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=0)\n",
    "\n",
    "~~~\n",
    "\n",
    "----\n",
    "\n",
    "#### <span style=\"color:blue\">4. 학습 후 성능 확인 </span>\n",
    "#### 각 모델마다 여러 하이퍼파라미터가 존재. 최적화된 파라미터를 구하는 sklearn api 는 두 개 \n",
    "\n",
    "1) `GridSearchCV`\n",
    "\n",
    "~~~python\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "~~~\n",
    "\n",
    "2) `RandomizedSearchCV`\n",
    "\n",
    "~~~python\n",
    "\n",
    "class sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
    "\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "~~~python\n",
    "\n",
    "fit(x_train, y_train)     ## 모수 추정(estimate)\n",
    "get_params()              ## 추정된 모수 확인\n",
    "predict(x_test)           ## x_test로부터 라벨 예측\n",
    "predict_log_proba(x_test) ## 로그 취한 확률 예측\n",
    "predict_proba(x_test)     ## 각 라벨로 예측될 확률\n",
    "score(x_test, y_test)     ## 모델 정확도 평가를 위한 mean accuracy\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "**Mean Accuarcy?**  \n",
    "\n",
    "~~~python\n",
    "\n",
    "#분류\n",
    "sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
    "\n",
    "#회귀\n",
    "sklearn.metrics.r2_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- 이 함수는 모델의 성능을 평가하기 위해 mean accuracy를 제공. 얼마나 맞췄는지 알아보기 위함. \n",
    "- 여러 척도가 존재. \n",
    "\n",
    "### 가장 높은 성능을 갖춘 hyperparameter 을 선택. 이 과정을 <span style=\"color:red\">hyper parameter tuning </span>이라고 함.   \n",
    "\n",
    "####   ->   이것을 가장 좋은 성능을 가진 모델이 나올 때까지 반복. \n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:blue\">6.우리가 최종 선택한 모델과 하이퍼파라미터로 예측하고자 하는 데이터 학습, 결과 얻기 </span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. 회귀분석\n",
    "\n",
    "- `종속변수와 독립변수 사이의 관계를 가장 잘 설명해주는 하나의 직선`을 구하는 것\n",
    "- y = b0 + b1x + b2x^2 + b3X^3.... 꼴\n",
    "- x는 독립변수..\n",
    "- 이러한 회귀식의 `모수`는 `최소제곱법`을 기준으로 만들어짐. \n",
    "\n",
    "#### 1. `Linear Regression`\n",
    "\n",
    "- 수치형 데이터 => 예측의 문제에서 사용하는 단순선형회귀\n",
    "- ex) 아파트 가격 예측 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dagunoh\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>size_sqft</th>\n",
       "      <th>min_to_subway</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_age_yrs</th>\n",
       "      <th>no_fee</th>\n",
       "      <th>has_roofdeck</th>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <th>has_doorman</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>has_dishwasher</th>\n",
       "      <th>has_patio</th>\n",
       "      <th>has_gym</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1545</td>\n",
       "      <td>2550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Upper East Side</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2472</td>\n",
       "      <td>11500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2919</td>\n",
       "      <td>4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>916</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2790</td>\n",
       "      <td>4795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3946</td>\n",
       "      <td>17500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4800</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Soho</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>7582</td>\n",
       "      <td>4210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>532</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>5686</td>\n",
       "      <td>6675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>988</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tribeca</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>9679</td>\n",
       "      <td>1699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Little Italy</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>5188</td>\n",
       "      <td>3475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>651</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Midtown West</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>4718</td>\n",
       "      <td>4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>816</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tribeca</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3539 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rental_id   rent  bedrooms  bathrooms  size_sqft  min_to_subway  floor  \\\n",
       "0          1545   2550       0.0          1        480              9    2.0   \n",
       "1          2472  11500       2.0          2       2000              4    1.0   \n",
       "2          2919   4500       1.0          1        916              2   51.0   \n",
       "3          2790   4795       1.0          1        975              3    8.0   \n",
       "4          3946  17500       2.0          2       4800              3    4.0   \n",
       "...         ...    ...       ...        ...        ...            ...    ...   \n",
       "3534       7582   4210       1.0          1        532              3    8.0   \n",
       "3535       5686   6675       2.0          2        988              5   10.0   \n",
       "3536       9679   1699       0.0          1        250              2    5.0   \n",
       "3537       5188   3475       1.0          1        651              6    5.0   \n",
       "3538       4718   4500       1.0          1        816              4   11.0   \n",
       "\n",
       "      building_age_yrs  no_fee  has_roofdeck  has_washer_dryer  has_doorman  \\\n",
       "0                   17       1             1                 0            0   \n",
       "1                   96       0             0                 0            0   \n",
       "2                   29       0             1                 0            1   \n",
       "3                   31       0             0                 0            1   \n",
       "4                  136       0             0                 0            1   \n",
       "...                ...     ...           ...               ...          ...   \n",
       "3534                16       1             1                 1            1   \n",
       "3535                 9       1             1                 1            1   \n",
       "3536                96       0             0                 0            0   \n",
       "3537                14       1             0                 1            1   \n",
       "3538                 9       0             1                 1            1   \n",
       "\n",
       "      has_elevator  has_dishwasher  has_patio  has_gym       neighborhood  \\\n",
       "0                1               1          0        1    Upper East Side   \n",
       "1                0               0          0        0  Greenwich Village   \n",
       "2                1               1          0        0            Midtown   \n",
       "3                1               1          0        1  Greenwich Village   \n",
       "4                1               1          0        1               Soho   \n",
       "...            ...             ...        ...      ...                ...   \n",
       "3534             1               1          0        1            Chelsea   \n",
       "3535             1               1          0        1            Tribeca   \n",
       "3536             0               0          0        0       Little Italy   \n",
       "3537             1               1          0        1       Midtown West   \n",
       "3538             1               0          1        1            Tribeca   \n",
       "\n",
       "        borough  \n",
       "0     Manhattan  \n",
       "1     Manhattan  \n",
       "2     Manhattan  \n",
       "3     Manhattan  \n",
       "4     Manhattan  \n",
       "...         ...  \n",
       "3534  Manhattan  \n",
       "3535  Manhattan  \n",
       "3536  Manhattan  \n",
       "3537  Manhattan  \n",
       "3538  Manhattan  \n",
       "\n",
       "[3539 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#다중선형회귀 실습 \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"Desktop/21Work/datasets/streeteasy/manhattan.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rental_id', 'rent', 'bedrooms', 'bathrooms', 'size_sqft',\n",
       "       'min_to_subway', 'floor', 'building_age_yrs', 'no_fee', 'has_roofdeck',\n",
       "       'has_washer_dryer', 'has_doorman', 'has_elevator', 'has_dishwasher',\n",
       "       'has_patio', 'has_gym', 'neighborhood', 'borough'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "\n",
    "#rent: 주택의 임대료\n",
    "#그 외의 항목들은 침실이 몇 개 있는지, 엘레베이터가 있는지, 식기세척기가 있는지 등 주택에 대한 다양한 정보. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data[['bedrooms', 'bathrooms', 'size_sqft', 'min_to_subway', 'floor', 'building_age_yrs', 'no_fee', 'has_roofdeck', 'has_washer_dryer', 'has_doorman', 'has_elevator', 'has_dishwasher', 'has_patio', 'has_gym']]\n",
    "y = data[['rent']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2)\n",
    "\n",
    "#선형회귀 모형에 학습\n",
    "\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3176.64736687],\n",
       "       [2984.55387237],\n",
       "       [5492.46357914],\n",
       "       [3556.4356723 ],\n",
       "       [3830.04459776],\n",
       "       [4797.73121042],\n",
       "       [2610.5766001 ],\n",
       "       [7999.34223221],\n",
       "       [6411.49443635],\n",
       "       [7882.0399207 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측값 \n",
    "y_predict = mlr.predict(x_test)\n",
    "#y_test\n",
    "y_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7714169419429884\n"
     ]
    }
   ],
   "source": [
    "#이 선형회귀 모델의 성능\n",
    "print(mlr.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 그려보기 \n",
    "\n",
    "plt.scatter(y_test, y_predict, alpha=0.4)\n",
    "plt.xlabel(\"Actual Rent\")\n",
    "plt.ylabel(\"Predicted Rent\")\n",
    "plt.title(\"MULTIPLE LINEAR REGRESSION\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. `Logistic Regression`\n",
    "\n",
    "- 데이터가 **어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측**하고 \n",
    "그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도 학습 알고리즘\n",
    "\n",
    "- 범주형 자료 => 분류 문제에서 사용하는 로지스틱회귀. \n",
    "- ex) A 라벨과 B 라벨 분류하기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종양 반응 : ['malignant' 'benign']\n",
      "target : [malignant:악성, benign: 양성]\n",
      "데이터 수 : 569\n",
      "데이터 열 이름 : ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "data 예시 :  [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    breast_cancer = datasets.load_breast_cancer()\n",
    "    print('종양 반응 :', breast_cancer.target_names)\n",
    "    print('target : [malignant:악성, benign: 양성]')\n",
    "    print('데이터 수 :', len(breast_cancer.data))\n",
    "    print('데이터 열 이름 :', breast_cancer.feature_names)\n",
    "    print('data 예시 : ', breast_cancer.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': '/Users/dagunoh/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/breast_cancer.csv'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>isCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  isCancer  \n",
       "0          0.4601                  0.11890         0  \n",
       "1          0.2750                  0.08902         0  \n",
       "2          0.3613                  0.08758         0  \n",
       "3          0.6638                  0.17300         0  \n",
       "4          0.2364                  0.07678         0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 정렬 \n",
    "\n",
    "data2= pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "sy = pd.Series(breast_cancer.target, dtype='category')\n",
    "data2['isCancer'] = sy\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30)\n",
      "(426,) (143,)\n"
     ]
    }
   ],
   "source": [
    "#독립변수, 종속변수 구분\n",
    "x = data2.loc[:, 'mean radius':'worst fractal dimension']\n",
    "y = data2['isCancer']\n",
    "\n",
    "#train, test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dagunoh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#x_test 넣었을 때 결과가 어떻게 되는지. \n",
    "#이 친구가 y_test랑 비슷할 수록 성능이 좋은 것. \n",
    "\n",
    "y_pred = lg.predict(x_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "print('정확도 :', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. 의사결정나무 (Decision Tree), RandomForest\n",
    "\n",
    "- 분류, 회귀 모두에게 쓰임\n",
    "\n",
    "- 훈련 과정에 구성한 다수의 결정 트리를 이용해 분류하거나, 평균 예측치를 출력함으로써 동작\n",
    "\n",
    "- 꽤 정확하고, 여러개의 입력 변수들을 다루는 것 가능. \n",
    "\n",
    "**왜 정확할까?**\n",
    "\n",
    "종속변수가 30개라 치면, 30개의 가지를 만들어서 분류해야하기 때문에 너무 많은 가지가 만들어질 것 -> 오버피팅. 하지만 랜덤으로 몇개의 종속변수만 설정해서 하나의 결정트리를 만들고, 또 이런식으로 계속 전개하면서 예측값들 중 가장 많이 나온 값을 최종 예측값으로 정하는 것. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>isCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  isCancer  \n",
       "0                  0.2654          0.4601                  0.11890         0  \n",
       "1                  0.1860          0.2750                  0.08902         0  \n",
       "2                  0.2430          0.3613                  0.08758         0  \n",
       "3                  0.2575          0.6638                  0.17300         0  \n",
       "4                  0.1625          0.2364                  0.07678         0  \n",
       "..                    ...             ...                      ...       ...  \n",
       "564                0.2216          0.2060                  0.07115         0  \n",
       "565                0.1628          0.2572                  0.06637         0  \n",
       "566                0.1418          0.2218                  0.07820         0  \n",
       "567                0.2650          0.4087                  0.12400         0  \n",
       "568                0.0000          0.2871                  0.07039         1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data2 #위의 Logistic regression에서 사용한 데이터 그대로 사용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30)\n",
      "(426,) (143,)\n"
     ]
    }
   ],
   "source": [
    "x = data2.loc[:, 'mean radius':'worst fractal dimension']\n",
    "y = data2['isCancer']\n",
    "\n",
    "#train, test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 13}\n",
      "최고 예측 정확도: 0.9437\n",
      "cross_val_score:  [0.94186047 0.95294118 0.91764706 0.94117647 0.97647059]\n"
     ]
    }
   ],
   "source": [
    "#하이퍼파라미터 튜닝\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [10, 11, 12, 13, 14,15,16,17,18,19, 20],\n",
    "           'max_depth' : [6, 8, 10, 12, 15, 18,],\n",
    "           'min_samples_leaf' : [8, 12, 18],\n",
    "           'min_samples_split' : [8, 16, 20]\n",
    "            }\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = kf, n_jobs = -1)\n",
    "grid_cv.fit(x_train, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "print('cross_val_score: ', cross_val_score(rf_clf,x_train,y_train,cv=kf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth= 6, min_samples_leaf =  8, min_samples_split =  20, n_estimators= 14)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    " \n",
    "# 예측\n",
    "y_pred = rf.predict(x_test)\n",
    " \n",
    "# 정확도 확인\n",
    "print('정확도 :', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443349753694582"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cross_val_score(rf_clf,x_test,y_test,cv=kf)\n",
    "sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SVM (support vector machine) \n",
    "\n",
    "- 주어진 데이터가 어느 카테고리에 속할지 판단. \n",
    "- Margin 최대화 하는 방향으로 => 이상치의 영향을 많이 받지 않음. \n",
    "- 비선형 분류에서도 사용 가능. \n",
    "\n",
    "- **parameter** : **gamma** = Gamma가 크면 decision boundary는 더 굴곡지고, Gamma가 작으면 decision boundary는 직선에 가까움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>isCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  isCancer  \n",
       "0                  0.2654          0.4601                  0.11890         0  \n",
       "1                  0.1860          0.2750                  0.08902         0  \n",
       "2                  0.2430          0.3613                  0.08758         0  \n",
       "3                  0.2575          0.6638                  0.17300         0  \n",
       "4                  0.1625          0.2364                  0.07678         0  \n",
       "..                    ...             ...                      ...       ...  \n",
       "564                0.2216          0.2060                  0.07115         0  \n",
       "565                0.1628          0.2572                  0.06637         0  \n",
       "566                0.1418          0.2218                  0.07820         0  \n",
       "567                0.2650          0.4087                  0.12400         0  \n",
       "568                0.0000          0.2871                  0.07039         1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred_svc = svm.predict(x_test)\n",
    "\n",
    "# 정확도 확인\n",
    "print('정확도 :', metrics.accuracy_score(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## `오늘의 실습`\n",
    "### [IDMB 영화 리뷰 감성분석]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dagunoh\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data3 = pd.read_csv('Desktop/Git/2021_Work/2021/text_analysis/labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 전처리 : html 태그 여전히 존재, 숫자 제거 등\n",
    "\n",
    "data3['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer #어간 추출\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "data3['review'] = data3['review'].str.replace('<br />',' ')\n",
    "data3['review'] = data3['review'].apply( lambda x : re.sub(\"[^a-zA-Z]\",' ',x))\n",
    "data3['review'] = data3['review'].str.lower()\n",
    "\n",
    "\n",
    "##불용어 제거\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data3['review'] = data3['review'].apply(lambda x: ' '.join(word for word \n",
    "                                             in x.split() if word not in stop_words))\n",
    "    \n",
    "##어간만!              \n",
    "ps = PorterStemmer()\n",
    "data3['review'] = data3['review'].apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        stuff go moment mj start listen music watch od...\n",
       "1        classic war world timothi hine entertain film ...\n",
       "2        film start manag nichola bell give welcom inve...\n",
       "3        must assum prais film greatest film opera ever...\n",
       "4        superbl trashi wondrous unpretenti exploit hoo...\n",
       "                               ...                        \n",
       "24995    seem like consider gone imdb review film went ...\n",
       "24996    believ made film complet unnecessari first fil...\n",
       "24997    guy loser get girl need build pick stronger su...\n",
       "24998    minut documentari bu uel made earli one spain ...\n",
       "24999    saw movi child broke heart stori unfinish end ...\n",
       "Name: review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500,), (7500,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data3['review']\n",
    "y = data3['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=156)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1692     girlfriend stun bad film minut would call quit...\n",
       "13392    expect script begin therefor noth director wor...\n",
       "21063    german film someth women come castl beyond rea...\n",
       "10335    richard tyler littl boy scare everyth like rid...\n",
       "16847    run group stop comedian exploit spent past mon...\n",
       "                               ...                        \n",
       "14848    like comment film script arriv halfway movi on...\n",
       "8450     first let say notori absolut charm film loving...\n",
       "8221     realist movi sure except fact charact look lik...\n",
       "10638    spend day dedic ron howard swear work entir un...\n",
       "20673    jerri spi tom listen creepi stori radio seiz o...\n",
       "Name: review, Length: 7500, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8831\n"
     ]
    }
   ],
   "source": [
    "print('예측 정확도는 {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
